import torch
import torch.backends.cudnn as cudnn
import torchvision
import torchvision.transforms as transforms
import torchvision.models as models
import torchvision.datasets as datasets

import torch.multiprocessing as mp
from torch.multiprocessing import Process, Queue, JoinableQueue
from torch.utils import data as D
from torch.autograd import Variable
import nvtx

from pathlib import Path
import shutil
import argparse
import random
import time
import os
import sys
import math

from shared_queues.trainer import RCNNProcTrainer
from shared.util import Counter, get_transformations, write_debug_indices

import datetime
import os
import time

import torch
import torch.utils.data
import torchvision
import torchvision.models.detection
import torchvision.models.detection.mask_rcnn
from torch_utils import utils
from torch_utils.coco_utils import get_coco
from torch_utils.group_by_aspect_ratio import create_aspect_ratio_groups, GroupedBatchSampler
from torch_utils.transforms import SimpleCopyPaste
from torch_utils import presets
from torchvision.transforms import InterpolationMode
from shared_queues.trainer import CocoTrainer

data_path = Path(os.environ["DATA_PATH"])

from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True

def collate_fn(batch):
    return tuple(zip(*batch))

def copypaste_collate_fn(batch):
    copypaste = SimpleCopyPaste(blending=True, resize_interpolation=InterpolationMode.BILINEAR)
    return copypaste(*collate_fn(batch))

def get_dataset(is_train, args):
    image_set = "train" if is_train else "val"
    paths = {"coco": (args.data_path, get_coco, 91)}
    p, ds_fn, num_classes = paths[args.dataset]

    ds = ds_fn(p, image_set=image_set, transforms=get_transform(is_train, args))
    return ds, num_classes


def get_transform(is_train, args):
    if is_train:
        return presets.DetectionPresetTrain(
            data_augmentation=args.data_augmentation, backend=args.backend, use_v2=args.use_v2
        )
    elif args.weights and args.test_only:
        weights = torchvision.models.get_weight(args.weights)
        trans = weights.transforms()
        return lambda img, target: (trans(img), target)
    else:
        return presets.DetectionPresetEval(backend=args.backend, use_v2=args.use_v2)

def get_args_parser(add_help=True):
    import argparse

    parser = argparse.ArgumentParser(description="PyTorch Detection Training", add_help=add_help)

    parser.add_argument('--num-processes', type=int, default=2)
    parser.add_argument('--training-workers', type=int, default=1)
    parser.add_argument('--validation-workers', type=int, default=1)
    parser.add_argument('--prefetch-factor', type=int, default=1)
    parser.add_argument('--seed', type=int, default=None)

    parser.add_argument('--use-dali', action='store_true', help="whether to use DALI for data-loading")
    parser.add_argument('--log-interval', type=int, default=10, metavar='N',
                        help='how many batches to wait before logging training status')
    parser.add_argument('-a','--arch', nargs='+', metavar='ARCH', help='model architecture (default: resnet18)', default='resnet18')

    parser.add_argument('--debug_data_dir', metavar='DIR', nargs='?', default='',
                        help='path to store data generated by dataloader')
    parser.add_argument('--overwrite_debug_data', type=int, default=1)
    parser.add_argument('--log_dir', metavar='LOG_DIR', nargs='?', default='',
                        help='path to store training log')
    parser.add_argument('--pretrained', nargs='+', metavar="PRETRAIN", help="Whether to pretrain a certain model")
    parser.add_argument('--dummy-data', action='store_true', help="use fake data to benchmark")
    parser.add_argument('--record_first_batch_time', action='store_true', help="Don't skip measuring time spent on first batch")

    parser.add_argument("--data-path", default="/datasets01/COCO/022719/", type=str, help="dataset path")
    parser.add_argument("--dataset", default="coco", type=str, help="dataset name")
    parser.add_argument("--model", default="maskrcnn_resnet50_fpn", type=str, help="model name")
    parser.add_argument("--device", default="cuda", type=str, help="device (Use cuda or cpu Default: cuda)")
    parser.add_argument(
        "-b", "--batch-size", default=2, type=int, help="images per gpu, the total batch size is $NGPU x batch_size"
    )
    parser.add_argument("--epochs", default=26, type=int, metavar="N", help="number of total epochs to run")
    parser.add_argument(
        "-j", "--workers", default=4, type=int, metavar="N", help="number of data loading workers (default: 4)"
    )
    parser.add_argument("--opt", default="sgd", type=str, help="optimizer")
    parser.add_argument(
        "--lr",
        default=0.02,
        type=float,
        help="initial learning rate, 0.02 is the default value for training on 8 gpus and 2 images_per_gpu",
    )
    parser.add_argument("--momentum", default=0.9, type=float, metavar="M", help="momentum")
    parser.add_argument(
        "--wd",
        "--weight-decay",
        default=1e-4,
        type=float,
        metavar="W",
        help="weight decay (default: 1e-4)",
        dest="weight_decay",
    )
    parser.add_argument(
        "--norm-weight-decay",
        default=None,
        type=float,
        help="weight decay for Normalization layers (default: None, same value as --wd)",
    )
    parser.add_argument(
        "--lr-scheduler", default="multisteplr", type=str, help="name of lr scheduler (default: multisteplr)"
    )
    parser.add_argument(
        "--lr-step-size", default=8, type=int, help="decrease lr every step-size epochs (multisteplr scheduler only)"
    )
    parser.add_argument(
        "--lr-steps",
        default=[16, 22],
        nargs="+",
        type=int,
        help="decrease lr every step-size epochs (multisteplr scheduler only)",
    )
    parser.add_argument(
        "--lr-gamma", default=0.1, type=float, help="decrease lr by a factor of lr-gamma (multisteplr scheduler only)"
    )
    parser.add_argument("--print-freq", default=20, type=int, help="print frequency")
    parser.add_argument("--output-dir", default=".", type=str, help="path to save outputs")
    parser.add_argument("--resume", default="", type=str, help="path of checkpoint")
    parser.add_argument("--start_epoch", default=0, type=int, help="start epoch")
    parser.add_argument("--aspect-ratio-group-factor", default=3, type=int)
    parser.add_argument("--rpn-score-thresh", default=None, type=float, help="rpn score threshold for faster-rcnn")
    parser.add_argument(
        "--trainable-backbone-layers", default=None, type=int, help="number of trainable layers of backbone"
    )
    parser.add_argument("--weights", default=None, type=str, help="the weights enum name to load")
    parser.add_argument("--weights-backbone", default=None, type=str, help="the backbone weights enum name to load")
    parser.add_argument(
        "--data-augmentation", default="hflip", type=str, help="data augmentation policy (default: hflip)"
    )
    parser.add_argument(
        "--sync-bn",
        dest="sync_bn",
        help="Use sync batch norm",
        action="store_true",
    )
    parser.add_argument(
        "--test-only",
        dest="test_only",
        help="Only test the model",
        action="store_true",
    )

    parser.add_argument(
        "--use-deterministic-algorithms", action="store_true", help="Forces the use of deterministic algorithms only."
    )

    # Use CopyPaste augmentation training parameter
    parser.add_argument(
        "--use-copypaste",
        action="store_true",
        help="Use CopyPaste data augmentation. Works only with data-augmentation='lsj'.",
    )

    parser.add_argument("--backend", default="PIL", type=str.lower, help="PIL or tensor - case insensitive")
    parser.add_argument("--use-v2", action="store_true", help="Use V2 transforms")

    return parser

import errno

def mkdir(path):
    try:
        os.makedirs(path)
    except OSError as e:
        if e.errno != errno.EEXIST:
            raise

def producer(loader, valid_loader, qs, device, args, producer_alive):
    pid = os.getpid()
    if args.seed:
        torch.manual_seed(args.seed)
    if args.debug_data_dir:
        if args.overwrite_debug_data:
            shutil.rmtree(args.debug_data_dir)
    debug_indices_path, debug_indices_val_path = None, None
    metric_logger = utils.MetricLogger(delimiter="  ")
    #metric_logger.add_meter("lr", utils.SmoothedValue(window_size=1, fmt="{value:.6f}"))
    print_freq = 100

    for epoch in range(1, args.epochs+1):
        header = f"Epoch: [{epoch}]"
        if args.debug_data_dir:
            debug_indices_path = Path(args.debug_data_dir) / f"epoch_{epoch}" / f"{pid}_producer_indices.txt"
            debug_indices_path.parent.mkdir(parents=True, exist_ok=True)

        nvtx.push_range("Start batch")
        for idx, (images, targets) in enumerate(metric_logger.log_every(loader, print_freq, header)):
            nvtx.pop_range()
            indices = None
            nvtx.push_range("memcpy")
            images = list(image.to(device) for image in images)
            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
            nvtx.pop_range()
            for q in qs:
                q.queue.put((idx, images, targets, epoch, "train", indices))

            metric_logger.update()
            nvtx.push_range("Start batch")
            #write_debug_indices(indices, debug_indices_path, args)

        # end of training for epoch, switch to eval
        if epoch > 2:
            if args.debug_data_dir:
                debug_indices_val_path = Path(args.debug_data_dir) / f"epoch_{epoch}" / f"{pid}_producer_val_indices.txt"
                debug_indices_val_path.parent.mkdir(parents=True, exist_ok=True)

            for idx, (inputs, labels) in enumerate(valid_loader):
                indices = None
                nvtx.push_range("memcpy")
                images = list(image.to(device) for image in images)
                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
                nvtx.pop_range()

                for q in qs:
                    q.queue.put((idx, inputs, labels, epoch, "valid", indices))

                #write_debug_indices(indices, debug_indices_val_path, args)
        
        for q in qs:
            q.queue.put((0, None, None, epoch, "end", None))
    producer_alive.wait()

class MyQueue(object):
    def __init__(self, queue, index):
        self.queue = queue
        self.index = index

class Logger(object):
    def __init__(self, args, pid, log_path=None, gpu_path=None):
        self.args = args
        self.pid = pid
        self.log_path = log_path
        self.gpu_path = gpu_path
        
        self.train_time = 0
        self.batch_time = 0
        self.val_acc = 0
        self.val_loss = 0
        self.val_correct = 0
        self.val_time = 0
    
    def log_train_interval(self, idx, epoch, num_items, loss, items_processed, train_time, batch_time):
        self.train_time = train_time
        self.batch_time = batch_time

        if idx % self.args.log_interval == 0:
            print('{}\tTrain Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.2f} Throughput [img/s]: {:.1f}'.format(
                self.pid, epoch, idx * num_items, self.args.train_dataset_len,
                100. * idx / self.args.train_loader_len, loss, items_processed/(train_time+batch_time)))

    def log_validation(self, val_loss, val_correct, val_acc, val_time):
        self.val_time = val_time
        self.val_acc = val_acc
        self.val_loss = val_loss
        self.val_correct = val_correct
        
    def log_write_epoch_end(self, epoch, epoch_time, train_acc, train_running_corrects):
        #print('{} Validation: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        #    self.pid, self.val_loss, self.val_correct, self.args.valid_dataset_len, self.val_acc))
        
        print(f"{self.pid} Epoch {epoch} end: {round(epoch_time,1)}s, Train accuracy: {round(train_acc,2)}")
        if self.args.log_dir:
            with open(self.log_path, "a") as f:
                f.write(f"{int(time.time())},{epoch},{train_acc},{self.val_acc},{self.train_time},{self.batch_time},{self.val_time},{epoch_time},{train_running_corrects},{self.val_correct}\n")
                os.system(f"nvidia-smi --query-compute-apps=gpu_uuid,pid,used_memory --format=csv,noheader >> {self.gpu_path}")

def worker(q, model, args, producer_alive, finished_workers):
    pid = os.getpid()
    log_path, gpu_path = None, None
    if model.on_device == False:
        print(f"{pid}\tTraining model: {args.model}")
        model.send_model()
        #model.scheduler.step()
        if args.log_dir:
            log_path, gpu_path = model.init_log(pid)
    
    logger = Logger(args, pid, log_path, gpu_path)    
    if not args.record_first_batch_time:
        print("Skipping recording batch time for first batch!")
    
    debug_indices_path, debug_indices_val_path = None, None

    epochs_processed = 0

    train_time, val_time, batch_time, items_processed = 0,0,0,0
    while True:
        pid = os.getpid()
        
        start = time.time()
        nvtx.push_range("Start get batch")
        idx, images, targets, epoch, batch_type, indices = q.queue.get()
        #images = list(image.to(args.device) for image in images)
        #targets = [{k: v.to(args.device) for k, v in t.items()} for t in targets]
        nvtx.pop_range()

        if idx == 0:
            model.start_epoch(epoch, args.train_loader_len)

        if args.debug_data_dir:
            debug_indices_path = Path(args.debug_data_dir) / args.model / f"{pid}_epoch_{epoch}" / "indices.txt"
            debug_indices_path.parent.mkdir(parents=True, exist_ok=True)
            debug_indices_val_path = Path(args.debug_data_dir) / args.model / f"{pid}_epoch_{epoch}" / "val_indices.txt"
            debug_indices_val_path.parent.mkdir(parents=True, exist_ok=True)

        if args.record_first_batch_time:
            batch_time += time.time() - start
        else:
            if idx > 0:
                batch_time += time.time() - start

        if idx % 100 == 0:
            print(f"Memory allocated (MB): {torch.cuda.max_memory_allocated() / (1024.0 * 1024.0)}")

        start = time.time()
        if batch_type == "train":
            #write_debug_indices(indices, debug_indices_path, args)

            nvtx.push_range("model forward")
            loss = model.forward(images, targets)
            nvtx.pop_range()

            train_time += time.time() - start

            #logger.log_train_interval(idx, epoch, len(images), loss_value, items_processed, train_time, batch_time)

        #elif batch_type == "valid":
            #write_debug_indices(indices, debug_indices_val_path, args)
            #inputs = Variable(inputs.to(args.device))
            #labels = Variable(labels.to(args.device))

            #val_loss, val_acc, val_correct = model.validate(inputs, labels)
            #val_time += time.time() - start
            #logger.log_validation(val_loss, val_correct, val_acc, val_time)
            
        elif batch_type == "end":
            train_epoch_acc, train_running_corrects = model.end_epoch(args)
            epoch_time = train_time + val_time + batch_time
            logger.log_write_epoch_end(epoch, epoch_time, train_epoch_acc, train_running_corrects)
            train_time, val_time, batch_time,items_processed = 0,0,0,0
            model.start_epoch(epoch+1, args.train_loader_len)

        q.queue.task_done()

        if batch_type == "end":
            epochs_processed += 1
            if epochs_processed == args.epochs:
                finished_workers.increment()
                if finished_workers.value() == args.num_processes:
                    producer_alive.set()
                break

def main(args):
    if args.backend.lower() == "datapoint" and not args.use_v2:
        raise ValueError("Use --use-v2 if you want to use the datapoint backend.")

    if args.output_dir:
        mkdir(args.output_dir)

    print(args)

    device = torch.device(args.device)

    if args.use_deterministic_algorithms:
        torch.use_deterministic_algorithms(True)

    # Data loading code
    print("Loading data")
    dataset, num_classes = get_dataset(is_train=True, args=args)
    dataset_test, _ = get_dataset(is_train=False, args=args)

    print("Creating data loaders")
    train_sampler = torch.utils.data.RandomSampler(dataset)
    test_sampler = torch.utils.data.SequentialSampler(dataset_test)

    if args.aspect_ratio_group_factor >= 0:
        group_ids = create_aspect_ratio_groups(dataset, k=args.aspect_ratio_group_factor)
        train_batch_sampler = GroupedBatchSampler(train_sampler, group_ids, args.batch_size)
    else:
        train_batch_sampler = torch.utils.data.BatchSampler(train_sampler, args.batch_size, drop_last=True)

    train_collate_fn = collate_fn
    if args.use_copypaste:
        if args.data_augmentation != "lsj":
            raise RuntimeError("SimpleCopyPaste algorithm currently only supports the 'lsj' data augmentation policies")

        train_collate_fn = copypaste_collate_fn

    data_loader = torch.utils.data.DataLoader(
        dataset, batch_sampler=train_batch_sampler, num_workers=args.workers, collate_fn=train_collate_fn
    )

    data_loader_test = torch.utils.data.DataLoader(
        dataset_test, batch_size=1, sampler=test_sampler, num_workers=args.workers, collate_fn=collate_fn
    )

    print("Creating model")
    kwargs = {"trainable_backbone_layers": args.trainable_backbone_layers}
    if args.data_augmentation in ["multiscale", "lsj"]:
        kwargs["_skip_resize"] = True
    if "rcnn" in args.model:
        if args.rpn_score_thresh is not None:
            kwargs["rpn_score_thresh"] = args.rpn_score_thresh
    model = torchvision.models.get_model(
        args.model, weights=args.weights, weights_backbone=args.weights_backbone, num_classes=num_classes, **kwargs
    )

    train_models = []
    for idx, arch in enumerate(["1",]):
        trainer = CocoTrainer(args, model, device)
        train_models.append(trainer)

    queues = []
    for idx in range(args.num_processes):
        q = JoinableQueue(maxsize=20)
        queue = MyQueue(q, idx)
        queues.append(queue)

    _start = time.time()

    producer_alive = mp.Event()
    producers = []

    for i in range(1):
        train_loader = data_loader
        
        valid_loader = data_loader_test

        args.train_dataset_len = 25000
        args.train_loader_len = 25000 / args.batch_size

        p = Process(target=producer, args = ((train_loader, valid_loader, queues, device, args, producer_alive)))
        producers.append(p)
        p.start()

    args.device = device
    finished_workers = Counter(0)
    workers = []
    for i in range(args.num_processes):
        p = Process(target=worker, daemon=True, args=((queues[i], train_models[i], args, producer_alive, finished_workers)))
        workers.append(p)
        p.start()

    for p in workers:
        p.join()


if __name__ == "__main__":
    args = get_args_parser().parse_args()
    main(args)